import numpy as np
import copy
import heapq
import time
from collections import defaultdict

# ==========================================
# I. ç»Ÿä¸€æ¯”èµ›ç¯å¢ƒ (RoboconEnvironment)
# ==========================================

class RoboconEnvironment:
    """
    ç»Ÿä¸€çš„æ¯”èµ›ç¯å¢ƒã€‚ç”¨äº AlphaBetaBot å’Œ AStarBot ä¹‹é—´çš„æ•°æ®äº¤äº’ã€‚
    ç©å®¶ 1 (Max/A* Bot) ä½¿ç”¨ +1ï¼Œç©å®¶ -1 (Min/AlphaBeta Bot) ä½¿ç”¨ -1ã€‚
    """
    def __init__(self, initial_board=None, initial_r1=5, initial_r2=5, initial_weapons=3, time_limit=180.0):
        # æ£‹ç›˜ç»“æ„: 3x3x2 æ•°ç»„ (Owner/Type)
        # board[r, c, 0] = Owner (1:P1, -1:P2, 0:Empty)
        # board[r, c, 1] = Type (1:R1-KFS, 2:R2-KFS, 0:Empty)
        if initial_board is None:
            self.board = np.zeros((3, 3, 2), dtype=int)
        else:
            self.board = initial_board.copy()
            
        # èµ„æº
        self.r1_kfs = {1: initial_r1, -1: initial_r1}
        self.r2_kfs = {1: initial_r2, -1: initial_r2}
        self.weapons = {1: initial_weapons, -1: initial_weapons}
        
        # æˆæœ¬/æ—¶é—´
        self.costs = {1: 0.0, -1: 0.0}
        self.time_limit = time_limit
        
        # å½“å‰ç©å®¶
        self.current_player = 1
        self.game_over = False
        self.winner = 0  # 1: P1 win, -1: P2 win, 0: Draw
        
        # åŠ¨ä½œæ—¶é—´ (ç®€åŒ–Roboconæ¨¡å‹)
        self.T_PLACE = {
            0: 8.0,  # é¡¶å±‚
            1: 5.0,  # ä¸­å±‚
            2: 5.0   # åº•å±‚
        }
        self.T_ATTACK = 6.0
        self.P_FAIL_PLACE = 0.1
        self.P_FAIL_ATTACK = 0.2

    def clone(self):
        new_env = RoboconEnvironment(
            initial_board=self.board, 
            initial_r1=self.r1_kfs[1], 
            initial_r2=self.r2_kfs[1], 
            initial_weapons=self.weapons[1],
            time_limit=self.time_limit
        )
        new_env.r1_kfs = self.r1_kfs.copy()
        new_env.r2_kfs = self.r2_kfs.copy()
        new_env.weapons = self.weapons.copy()
        new_env.costs = self.costs.copy()
        new_env.current_player = self.current_player
        new_env.game_over = self.game_over
        new_env.winner = self.winner
        return new_env

    def _get_cost(self, action_type, pos=None):
        """è®¡ç®—åŠ¨ä½œçš„é£é™©åŠ æƒæˆæœ¬"""
        if action_type == 'place':
            r = pos[0]
            cost_time = self.T_PLACE.get(r, 5.0)
            return cost_time / (1.0 - self.P_FAIL_PLACE)
        elif action_type == 'attack':
            return self.T_ATTACK / (1.0 - self.P_FAIL_ATTACK)
        return 0.0

    def get_valid_actions(self):
        actions = []
        # æ£€æŸ¥å½“å‰ç©å®¶çš„æ—¶é—´æ˜¯å¦è€—å°½
        if self.game_over or self.costs[self.current_player] >= self.time_limit:
            return actions

        player = self.current_player
        
        # --- æ”¾ç½®åŠ¨ä½œ ---
        for r in range(3):
            for c in range(3):
                if self.board[r, c, 0] == 0:
                    pos = (r, c)
                    # æ”¾ç½® R1-KFS (Type 1)
                    if self.r1_kfs[player] > 0:
                        actions.append({
                            'type': 'place', 'kfs_type': 1, 'pos': pos, 'player': player
                        })
                    # æ”¾ç½® R2-KFS (Type 2)
                    if self.r2_kfs[player] > 0:
                        actions.append({
                            'type': 'place', 'kfs_type': 2, 'pos': pos, 'player': player
                        })
        
        # --- æ”»å‡»åŠ¨ä½œ ---
        if self.weapons[player] > 0:
            for r in range(3):
                for c in range(3):
                    # æ”»å‡»å¯¹æ–¹çš„æ£‹å­
                    if self.board[r, c, 0] == -player:
                        pos = (r, c)
                        actions.append({
                            'type': 'attack', 'pos': pos, 'player': player
                        })
        
        return actions

    def step(self, action):
        """æ‰§è¡Œä¸€ä¸ªåŠ¨ä½œ"""
        action_type = action['type']
        pos = action['pos']
        player = action['player']
        
        cost = self._get_cost(action_type, pos)
        
        if action_type == 'place':
            kfs_type = action['kfs_type']
            self.board[pos[0], pos[1], 0] = player
            self.board[pos[0], pos[1], 1] = kfs_type
            if kfs_type == 1:
                self.r1_kfs[player] -= 1
            else:
                self.r2_kfs[player] -= 1
        
        elif action_type == 'attack':
            self.board[pos[0], pos[1], 0] = 0
            self.board[pos[0], pos[1], 1] = 0
            self.weapons[player] -= 1
        
        self.costs[player] += cost
        
        # æ£€æŸ¥æ¸¸æˆæ˜¯å¦ç»“æŸ (åªéœ€è¦æ£€æŸ¥ç»å¯¹èƒœåˆ©)
        self._check_grand_master_win()
        
        # åˆ‡æ¢ç©å®¶ (åœ¨ duel æ¨¡æ‹Ÿå™¨ä¸­åˆ¤æ–­æ˜¯å¦è·³è¿‡)
        if not self.game_over:
            self.current_player = -self.current_player

    def _get_score(self, player):
        """è®¡ç®—æŒ‡å®šç©å®¶çš„å¾—åˆ†"""
        score = 0
        for r in range(3):
            for c in range(3):
                if self.board[r, c, 0] == player:
                    kfs_type = self.board[r, c, 1]
                    
                    # R1 (type 1): 40/60/90; R2 (type 2): 50/70/100
                    if r == 0:  # é¡¶å±‚åŒºåŸŸ
                        score += 90 if kfs_type == 1 else 100
                    elif r == 1:  # ä¸­å±‚åŒºåŸŸ
                        score += 60 if kfs_type == 1 else 70
                    elif r == 2:  # åº•å±‚åŒºåŸŸ
                        score += 40 if kfs_type == 1 else 50
        return score
    
    def _check_grand_master(self, player):
        """æ£€æŸ¥æŒ‡å®šç©å®¶æ˜¯å¦è¾¾æˆç»å¯¹èƒœåˆ© (ä¸‰è¿ä¸”å«R2)"""
        
        # åˆ›å»ºä¸€ä¸ªåªåŒ…å« Owner çš„ 3x3 çŸ©é˜µ
        owner_board = self.board[:, :, 0]
        
        # æ£€æŸ¥æ‰€æœ‰è¡Œ/åˆ—/å¯¹è§’çº¿
        for i in range(3):
            # æ£€æŸ¥åˆ—
            if np.all(owner_board[:, i] == player):
                types = self.board[:, i, 1]
                if 2 in types: 
                    return True
            # æ£€æŸ¥è¡Œ
            if np.all(owner_board[i, :] == player):
                types = self.board[i, :, 1]
                if 2 in types: 
                    return True
        
        # æ£€æŸ¥å¯¹è§’çº¿
        diag1_owner = owner_board.diagonal()
        diag2_owner = np.fliplr(owner_board).diagonal()
        
        if np.all(diag1_owner == player):
            types = self.board.diagonal()[:, 1]
            if 2 in types: 
                return True
            
        if np.all(diag2_owner == player):
            # ç›´æ¥ä»åŸå§‹ board ä¸­æŠ½å–åå‘å¯¹è§’çº¿ç±»å‹
            types = np.array([self.board[i, 2-i, 1] for i in range(3)]) 
            if 2 in types: 
                return True
            
        return False
    
    def _check_grand_master_win(self):
        """æ£€æŸ¥ç»å¯¹èƒœåˆ©ï¼Œå¹¶è®¾ç½® game_over/winner"""
        # 1. ç»å¯¹èƒœåˆ©æ£€æŸ¥ (Robocon ç»ˆå±€è§„åˆ™)
        if self._check_grand_master(1):
            self.game_over = True
            self.winner = 1
            return
        if self._check_grand_master(-1):
            self.game_over = True
            self.winner = -1
            return
            
    def _get_game_end_score_winner(self):
        """æ¸¸æˆç»“æŸæ—¶ï¼Œæ ¹æ®åˆ†æ•°åˆ¤æ–­èƒœè€…"""
        self.game_over = True
        score_p1 = self._get_score(1)
        score_p2 = self._get_score(-1)
        
        if score_p1 > score_p2:
            self.winner = 1
        elif score_p2 > score_p1:
            self.winner = -1
        else:
            self.winner = 0  # å¹³å±€

    def get_valid_actions_no_time_check(self, player):
        """ç”¨äºåˆ¤æ–­æ¸¸æˆæ˜¯å¦ç»“æŸæ—¶ï¼Œæ£€æŸ¥èµ„æºæ˜¯å¦è€—å°½ã€‚è¿”å›å®é™…çš„åŠ¨ä½œåˆ—è¡¨ã€‚"""
        actions = []
        # --- æ”¾ç½®åŠ¨ä½œ ---
        for r in range(3):
            for c in range(3):
                if self.board[r, c, 0] == 0:
                    pos = (r, c)
                    if self.r1_kfs[player] > 0: 
                        actions.append({'type': 'place', 'kfs_type': 1, 'pos': pos, 'player': player})
                    if self.r2_kfs[player] > 0: 
                        actions.append({'type': 'place', 'kfs_type': 2, 'pos': pos, 'player': player})
        
        # --- æ”»å‡»åŠ¨ä½œ ---
        if self.weapons[player] > 0:
            for r in range(3):
                for c in range(3):
                    if self.board[r, c, 0] == -player:
                        actions.append({'type': 'attack', 'pos': (r, c), 'player': player})

        return actions
    
    def display(self):
        """æ˜¾ç¤ºå½“å‰æ¸¸æˆçŠ¶æ€"""
        print("\n" + "="*40)
        print("å½“å‰æ¸¸æˆçŠ¶æ€:")
        print(f"å½“å‰ç©å®¶: {'Player 1' if self.current_player == 1 else 'Player -1'}")
        print(f"æ¸¸æˆç»“æŸ: {self.game_over}, èƒœåˆ©è€…: {self.winner}")
        print(f"æ—¶é—´æ¶ˆè€—: P1={self.costs[1]:.1f}s, P-1={self.costs[-1]:.1f}s")
        print(f"èµ„æº: P1 R1={self.r1_kfs[1]}, R2={self.r2_kfs[1]}, æ­¦å™¨={self.weapons[1]}")
        print(f"èµ„æº: P-1 R1={self.r1_kfs[-1]}, R2={self.r2_kfs[-1]}, æ­¦å™¨={self.weapons[-1]}")
        
        print("\næ£‹ç›˜ (æ‰€æœ‰è€…:ç±»å‹):")
        print("  " + "-" * 19)
        for r in range(3):
            row_str = "  |"
            for c in range(3):
                owner = self.board[r, c, 0]
                kfs_type = self.board[r, c, 1]
                if owner == 1:
                    symbol = f"P1:{kfs_type}"
                elif owner == -1:
                    symbol = f"P-1:{kfs_type}"
                else:
                    symbol = "   "
                row_str += f" {symbol:4s} |"
            print(row_str)
            print("  " + "-" * 19)
        print(f"å¾—åˆ†: P1={self._get_score(1)}, P-1={self._get_score(-1)}")
        print("="*40)

# ==========================================
# II. AlphaBeta Bot (Player -1)
# ==========================================

class AlphaBetaBot:
    def __init__(self, depth=3):
        self.search_depth = depth

    def get_best_move(self, env):
        actions = env.get_valid_actions()
        if not actions:
            return None

        best_val = float('inf')  # AlphaBetaBot æ‰®æ¼” Player -1 (Min)
        best_action = None

        # æ ¹èŠ‚ç‚¹éå†
        is_maximizing = True  # å› ä¸ºä¸‹ä¸€æ­¥æ˜¯å¯¹æ–¹(P1)èµ°

        for action in actions:
            next_env = env.clone()
            next_env.step(action)
            
            # é€’å½’æœç´¢
            val = self._alpha_beta(next_env, self.search_depth - 1, -float('inf'), float('inf'), is_maximizing)
            
            if val < best_val:
                best_val = val
                best_action = action

        return best_action

    def _alpha_beta(self, env, depth, alpha, beta, is_maximizing):
        # --- 1. ç»ˆæ­¢æ¡ä»¶ ---
        if depth == 0 or env.game_over:
            return self._evaluate(env)

        # ä¿®æ­£: æ£€æŸ¥å½“å‰ç©å®¶æ˜¯å¦è¿˜æœ‰åˆæ³•åŠ¨ä½œï¼ˆåœ¨æ—¶é—´é™åˆ¶å†…ï¼‰
        actions = env.get_valid_actions()
        if not actions: 
            # å¦‚æœå½“å‰ç©å®¶æ— åŠ¨ä½œï¼Œç›´æ¥è¯„ä¼°å½“å‰çŠ¶æ€
            return self._evaluate(env)

        # --- 2. é€’å½’æœç´¢ ---
        if is_maximizing:  # Player 1 (Max)
            max_eval = -float('inf')
            for action in actions:
                next_env = env.clone()
                next_env.step(action)
                eval_val = self._alpha_beta(next_env, depth - 1, alpha, beta, False)
                max_eval = max(max_eval, eval_val)
                alpha = max(alpha, eval_val)
                if beta <= alpha:
                    break
            return max_eval
        else:  # Player -1 (Min)
            min_eval = float('inf')
            for action in actions:
                next_env = env.clone()
                next_env.step(action)
                eval_val = self._alpha_beta(next_env, depth - 1, alpha, beta, True)
                min_eval = min(min_eval, eval_val)
                beta = min(beta, eval_val)
                if beta <= alpha:
                    break
            return min_eval

    def _evaluate(self, env):
        """ é™æ€è¯„ä¼°å‡½æ•°ï¼šæ­£åˆ† -> P1 æœ‰åˆ©ï¼›è´Ÿåˆ† -> P2 (-1) æœ‰åˆ© """
        P1 = 1
        P2 = -1
        score = 0.0

        # --- A. ç»ˆå±€è¯„åˆ† (å·¨å¤§å¥–åŠ±/æƒ©ç½š) ---
        if env.game_over:
            # ä½¿ç”¨ä¸€ä¸ªæå¤§çš„å€¼ï¼Œä¿è¯ç»ˆå±€åˆ¤å®šä¼˜å…ˆ
            if env.winner == P1:
                return 1000000.0 - env.costs[P1]
            elif env.winner == P2:
                return -1000000.0 + env.costs[P2]
            else:  # å¹³å±€
                # ç»ˆå±€æ—¶çš„å¾—åˆ†å·®ä½œä¸ºå¹³å±€çš„tie-breaker
                return env._get_score(P1) - env._get_score(P2) 

        # --- B. è¿‡ç¨‹è¯„åˆ† (åŸºäº Robocon Score & ç›˜é¢ä¼˜åŠ¿) ---
        
        # 1. å®é™…å¾—åˆ†ä¼˜åŠ¿
        score += 1.0 * (env._get_score(P1) - env._get_score(P2))

        # 2. ç»å¯¹èƒœåˆ©å¨èƒ
        owner_board = env.board[:, :, 0]
        lines = []
        lines.extend([owner_board[:, i] for i in range(3)])  # åˆ—
        lines.extend([owner_board[i, :] for i in range(3)])  # è¡Œ
        lines.append(owner_board.diagonal())                 # å¯¹è§’1
        lines.append(np.fliplr(owner_board).diagonal())      # å¯¹è§’2

        for line in lines:
            cnt_p1 = np.sum(line == P1)
            cnt_p2 = np.sum(line == P2)

            if cnt_p2 == 0:
                if cnt_p1 == 2: 
                    score += 500.0  # P1 å·®ä¸€æ­¥è¿çº¿
                elif cnt_p1 == 1: 
                    score += 50.0

            if cnt_p1 == 0:
                if cnt_p2 == 2: 
                    score -= 500.0  # P2 å·®ä¸€æ­¥è¿çº¿
                elif cnt_p2 == 1: 
                    score -= 50.0

        # 3. èµ„æºä¼˜åŠ¿
        score += 10.0 * (env.r2_kfs[P1] - env.r2_kfs[P2])
        score += 5.0 * (env.weapons[P1] - env.weapons[P2])
        
        # 4. æ—¶é—´åŠ£åŠ¿
        score += (env.costs[P2] - env.costs[P1]) * 0.1

        return score

# ==========================================
# III. A* Bot (Player +1)
# ==========================================

class AStarBot:
    """
    åŸºäºæ··åˆç›®æ ‡ A* çš„å•æ­¥å†³ç­–è€… (ä»…åœ¨å•æ­¥åŠ¨ä½œä¸­è¿›è¡Œæ·±åº¦å¯å‘å¼è¯„ä¼°)
    """
    def __init__(self):
        # A* æ ¸å¿ƒå‚æ•°
        self.P_WIN = 1000.0  # ç»å¯¹èƒœåˆ©çš„å·¨å¤§æƒ©ç½šé¡¹
        self.W_SCORE = 1.0   # å¾—åˆ†åç½®æƒé‡

    def get_best_move(self, env):
        actions = env.get_valid_actions()
        if not actions:
            return None

        best_f_mixed = float('inf')  # A* Bot (P1) å¯»æ±‚æœ€å°çš„ F_mixed
        best_action = None
        
        for action in actions:
            next_env = env.clone()
            next_env.step(action)
            
            # --- è½¬æ¢ä¸º GameState æ–¹ä¾¿ H(n) è®¡ç®— ---
            temp_state = self._convert_env_to_state(next_env)
            
            # --- è®¡ç®— H(n) (æ··åˆå¯å‘å¼) ---
            h_mixed = self._heuristic(temp_state, env)

            # --- è®¡ç®— F_mixed = G(n) + H(n) ---
            f_mixed = next_env.costs[1] + h_mixed
            
            if f_mixed < best_f_mixed:
                best_f_mixed = f_mixed
                best_action = action

        return best_action

    def _convert_env_to_state(self, env):
        """å°† numpy ç¯å¢ƒè½¬æ¢ä¸º A* å‹å¥½çš„åˆ—è¡¨ç»“æ„"""
        board_list = []
        for r in range(3):
            row = []
            for c in range(3):
                owner = env.board[r, c, 0]
                kfs_type = env.board[r, c, 1]
                row.append({'owner': owner, 'type': kfs_type})
            board_list.append(row)
            
        return GameStateDummy(
            board=board_list,
            r1_kfs=env.r1_kfs[1],
            r2_kfs=env.r2_kfs[1],
            weapons=env.weapons[1]
        )

    def _calculate_h_gm(self, state, env):
        """è®¡ç®— H_GM: é¢„ä¼°è¾¾æˆç»å¯¹èƒœåˆ©æ‰€éœ€çš„æœ€å°æ—¶é—´ (åªçœ‹ P1 è§†è§’)"""
        if env._check_grand_master(1): 
            return 0, 0 

        min_steps_needed = 9 
        
        # æ£€æŸ¥æ‰€æœ‰è¿çº¿
        indices = []
        for c in range(3): 
            indices.append([(r, c) for r in range(3)])  # åˆ—
        for r in range(3): 
            indices.append([(r, c) for c in range(3)])  # è¡Œ
        indices.append([(i, i) for i in range(3)])
        indices.append([(i, 2-i) for i in range(3)])
        
        for line_idx in indices:
            my_count, enemy_count, r2_present = 0, 0, False
            for r, c in line_idx:
                cell = state.board[r][c]
                if cell['owner'] == 1: 
                    my_count += 1
                    if cell['type'] == 2: 
                        r2_present = True
                elif cell['owner'] == -1: 
                    enemy_count += 1
            
            steps = 0
            # æ”»å‡»æ•Œäºº
            if enemy_count > 0:
                if state.weapons >= enemy_count: 
                    steps += enemy_count * env._get_cost('attack')
                else: 
                    continue  # æ— æ³•æ¸…ç†éšœç¢
            
            # æ”¾ç½®æ‰€éœ€å­
            needed_placements = 3 - my_count - enemy_count
            if needed_placements < 0: 
                needed_placements = 0
            
            # å‡è®¾æ‰€æœ‰æ”¾ç½®éƒ½å‘ç”Ÿåœ¨ä»£ä»·æœ€å°çš„åº•å±‚ (r=2)
            steps += needed_placements * env.T_PLACE[2] 
            
            # æ£€æŸ¥ R2-KFS èµ„æºæ˜¯å¦è¶³å¤Ÿ
            r2_needed = 0
            if needed_placements > 0 and not r2_present:
                # è‡³å°‘éœ€è¦ä¸€ä¸ª R2
                r2_needed = 1 
            
            if r2_needed > state.r2_kfs:
                continue  # R2 èµ„æºä¸è¶³
                
            # è®¡ç®—æ€»æ­¥æ•°ï¼ˆç®€åŒ–ä¸ºæ—¶é—´ï¼‰
            total_time = steps
            if total_time < min_steps_needed:
                min_steps_needed = total_time
                
        H_GM = min_steps_needed 
        # è¿”å›æ€»è€—æ—¶å’Œç®€åŒ–åçš„æ­¥æ•°
        return H_GM, min_steps_needed / env.T_PLACE[2] if env.T_PLACE[2] > 0 else 9

    def _heuristic(self, state, env):
        """è®¡ç®— F_mixed çš„ H(n) éƒ¨åˆ†: H_GM - ScoreBias + WinBonus"""
        H_GM, min_steps = self._calculate_h_gm(state, env)
        
        P_win = self.P_WIN
        
        # WinBonus
        if env._check_grand_master(1):
            win_bonus = -P_win  # å·²è¾¾æˆ
        elif H_GM < 3 * env.T_PLACE[2]: 
            win_bonus = -P_win + H_GM  # é¢„ä¼°å¯è¾¾æˆ
        else:
            win_bonus = 0.0
            
        # ScoreBias
        score_bias = self.W_SCORE * env._get_score(1)
        
        return H_GM - score_bias + win_bonus

# --- A* å†…éƒ¨ä½¿ç”¨çš„ç®€åŒ–çŠ¶æ€ç±» ---
class GameStateDummy:
    """A* å†…éƒ¨è®¡ç®— H(n) æ—¶ä½¿ç”¨çš„ä¸´æ—¶çŠ¶æ€"""
    def __init__(self, board, r1_kfs, r2_kfs, weapons):
        self.board = board
        self.r1_kfs = r1_kfs
        self.r2_kfs = r2_kfs
        self.weapons = weapons

# ==========================================
# IV. å¯¹æŠ—èµ›æ¨¡æ‹Ÿå™¨ (Duel Simulator)
# ==========================================

def run_duel(bot1, bot2, num_rounds=500):
    p1_wins = 0
    p2_wins = 0
    draws = 0

    print(f"--- âš”ï¸ å¼€å§‹ {num_rounds} è½®å¯¹æˆ˜ (P1: A* Bot, P2: AlphaBeta Bot) âš”ï¸ ---")
    
    for i in range(1, num_rounds + 1):
        # æ¯æ¬¡å¯¹æˆ˜é‡ç½®ç¯å¢ƒ
        env = RoboconEnvironment()
        
        no_action_count = 0  # è·Ÿè¸ªè¿ç»­æ— åŠ¨ä½œçš„æ¬¡æ•°
        
        # è½®æµèµ°
        while not env.game_over:
            
            # --- 1. è·å–åŠ¨ä½œ ---
            if env.current_player == 1:
                action = bot1.get_best_move(env)
            else:  # Player -1
                action = bot2.get_best_move(env)
            
            # --- 2. å¤„ç†æ— åŠ¨ä½œ (å…³é”®ä¿®å¤ç‚¹) ---
            if action is None:
                no_action_count += 1
                
                # æ£€æŸ¥**åŒæ–¹**æ˜¯å¦éƒ½æ— åŠ¨ä½œ æˆ– åŒæ–¹æ—¶é—´éƒ½è€—å°½
                actions_p1 = env.get_valid_actions_no_time_check(1)
                actions_p2 = env.get_valid_actions_no_time_check(-1)
                
                p1_no_valid_moves = (len(actions_p1) == 0 or env.costs[1] >= env.time_limit)
                p2_no_valid_moves = (len(actions_p2) == 0 or env.costs[-1] >= env.time_limit)
                
                # ç»ˆæ­¢æ¡ä»¶ï¼šåŒæ–¹éƒ½æ— æ³•èµ°æ£‹
                if p1_no_valid_moves and p2_no_valid_moves:
                    env._get_game_end_score_winner()  # æ ¹æ®å¾—åˆ†å†³å®šèƒœè´Ÿ
                    break 
                
                # åªæœ‰å½“å‰ç©å®¶æ²¡åŠ¨ä½œï¼Œåˆ™åˆ‡æ¢åˆ°å¦ä¸€ä¸ªç©å®¶ç»§ç»­
                env.current_player = -env.current_player
                
                # å¦‚æœè¿ç»­ä¸¤æ¬¡éƒ½æ²¡æœ‰åŠ¨ä½œï¼Œåˆ™ç›´æ¥æ ¹æ®å¾—åˆ†åˆ¤æ–­èƒœè´Ÿï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
                if no_action_count > 2: 
                    env._get_game_end_score_winner()
                    break
                
                continue  # è¿›å…¥ä¸‹ä¸€è½®å¾ªç¯ï¼Œæ¢äººèµ°
            
            # --- 3. æ‰§è¡ŒåŠ¨ä½œ ---
            env.step(action)
            no_action_count = 0  # æˆåŠŸæ‰§è¡ŒåŠ¨ä½œï¼Œé‡ç½®è®¡æ•°

        if env.winner == 1:
            p1_wins += 1
        elif env.winner == -1:
            p2_wins += 1
        else:
            draws += 1
            
        if i % 100 == 0:
            print(f"  [è¿›åº¦] å®Œæˆ {i} è½®...")

    print("--- ğŸ å¯¹æˆ˜ç»“æŸ ğŸ ---")
    
    total_rounds = num_rounds
    p1_win_rate = (p1_wins / total_rounds) * 100
    p2_win_rate = (p2_wins / total_rounds) * 100
    draw_rate = (draws / total_rounds) * 100
    
    return p1_wins, p2_wins, draws, p1_win_rate, p2_win_rate, draw_rate

# ==========================================
# V. ä¸»ç¨‹åºæ‰§è¡Œ
# ==========================================

if __name__ == "__main__":
    print("=" * 60)
    print("           Robocon AI å¯¹æˆ˜ç³»ç»Ÿ (ä¿®å¤ç‰ˆ)")
    print("          A* Bot vs AlphaBeta Bot")
    print("=" * 60)
    
    # é…ç½® Bots
    ab_bot = AlphaBetaBot(depth=3) 
    a_star_bot = AStarBot()
    
    # ä¸ºäº†æ¼”ç¤ºï¼Œå‡å°‘è½®æ•°ä»¥åŠ å¿«é€Ÿåº¦ï¼ˆå®Œæ•´æµ‹è¯•å»ºè®®500è½®ï¼‰
    NUM_ROUNDS = 50
    
    print(f"å¯¹æˆ˜è½®æ•°: {NUM_ROUNDS} è½®")
    print(f"A* Bot (Player 1): å•æ­¥å¯å‘å¼æœç´¢")
    print(f"AlphaBeta Bot (Player -1): æ·±åº¦ {ab_bot.search_depth}")
    print("\næ³¨æ„ï¼šAlphaBetaæœç´¢æ·±åº¦ä¸º3ï¼Œéœ€è¦ä¸€å®šè®¡ç®—æ—¶é—´")
    print("     è¯·è€å¿ƒç­‰å¾…å¯¹æˆ˜ç»“æœ...")
    print()
    
    # è¿è¡Œå¯¹æˆ˜
    start_time = time.time()
    p1_wins, p2_wins, draws, p1_win_rate, p2_win_rate, draw_rate = run_duel(
        bot1=a_star_bot,  # Player 1: A* Bot
        bot2=ab_bot,      # Player -1: AlphaBeta Bot
        num_rounds=NUM_ROUNDS
    )
    end_time = time.time()
    
    # --- è¾“å‡ºç»“æœ ---
    print("\n" + "="*60)
    print("ğŸ† æœ€ç»ˆå¯¹æˆ˜ç»“æœ (åŸºäº Robocon ç®€åŒ–è§„åˆ™) ğŸ†")
    print("="*60)
    print(f"æ€»å›åˆæ•°: {NUM_ROUNDS}")
    print(f"æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")
    print("-" * 60)
    print(f"A* Bot (Player 1) è·èƒœæ¬¡æ•°: {p1_wins}")
    print(f"AlphaBeta Bot (Player -1) è·èƒœæ¬¡æ•°: {p2_wins}")
    print(f"å¹³å±€æ¬¡æ•°: {draws}")
    print("-" * 60)
    print(f"A* Bot (Player 1) èƒœç‡: {p1_win_rate:.2f}%")
    print(f"AlphaBeta Bot (Player -1) èƒœç‡: {p2_win_rate:.2f}%")
    print(f"å¹³å±€ç‡: {draw_rate:.2f}%")
    print("="*60)
    
    # æ‰“å°ç®€è¦åˆ†æ
    print("\nç®€è¦åˆ†æ:")
    if p1_win_rate > p2_win_rate:
        print("âœ… A* Bot è¡¨ç°æ›´ä¼˜")
        print("   ä¼˜åŠ¿: æ›´æ³¨é‡å¾—åˆ†å’Œæ—¶é—´æ•ˆç‡")
    elif p2_win_rate > p1_win_rate:
        print("âœ… AlphaBeta Bot è¡¨ç°æ›´ä¼˜")
        print("   ä¼˜åŠ¿: æ·±åº¦æœç´¢ï¼Œæ›´æ³¨é‡å¨èƒè¯„ä¼°")
    else:
        print("ğŸ¤ åŒæ–¹è¡¨ç°ç›¸å½“")
    
    print("\næ¸¸æˆè§„åˆ™:")
    print("- èƒœåˆ©æ¡ä»¶: è¾¾æˆç»å¯¹èƒœåˆ© (ä¸€æ•´è¡Œ/åˆ—/å¯¹è§’çº¿ä¸”åŒ…å«R2-KFS)")
    print("- æ—¶é—´é™åˆ¶: 180ç§’/ç©å®¶")
    print("- èµ„æº: 5ä¸ªR1-KFS, 5ä¸ªR2-KFS, 3ä¸ªæ­¦å™¨")
    print("- è¯„åˆ†: R1/R2åœ¨ä¸åŒå±‚æœ‰ä¸åŒåˆ†æ•°")
